# POPL 2022 Artifact Evaluation instructions

We were unable to get a VirtualBox VM running under macOS Big Sur, so we provide a Docker-based artifact instead.

## List of supported claims

The artifact consists of an implementation, in PureScript, of the programming language described in the paper (called _Fluid_ in the non-anonymised submission). More specifically, the artifact implements:
- the core language described in § 2;
- the bidirectional analysis described in § 3, and its De Morgan dual as described in § 4;
- the surface language described in § 5.

The specific claims supported by the artifact relate to the following 4 figures in the paper.

### Figure 1

[§ 4, second sentence] "In particular [forward evaluation] can answer questions like: “what data is needed to compute this bar in a bar chart?”, and indeed **we were able to use our implementation to generate Figure 1**." The function ```linkingFigs``` in `src\app\Demo.purs` generates 6 output images; 4 of these were combined to produce Figure 1. See Evaluation Step 1.

### Figure 2

[§ 4.1, final sentence] "This is the approach implemented in Fluid, and **we used this to generate Figure 2** in § 1.2". Of the 6 images produced by ```linkingFigs```, 3 were combined to produce Figure 2. See Evaluation Step 2.

### Figure 13

[§ 4.2, paragraph 2] "**Fluid was used to generate the diagrams in Figure 13**..." The function ```convolutionFigs``` in `src\app\Demo.purs` generates 9 output images which were combined to produce Figure. 13. See Evaluation Step 3.

### Figure 16

[§ 5.1, paragraph 1] "**Figure 16 shows how the end-to-end mapping would appear to a user.**" The function ```testBwd``` of `src\test\Main.purs` runs the test `section-5-example`, which generates the raw information required for Figure 16. See Evaluation Step 4.

## Download, installation, and sanity-check

### Software required

- git
- Docker; we have tested with Docker Desktop 4.1.0 for macOS

### Obtaining the artifact

Follow the following steps:
- `git clone https://github.com/explorable-viz/fluid.git` to get this repo
- check out tag `v0.4.1`
- ensure Docker service is running
- in the repository root, run `docker build -t fluid-webapp .` to build Docker image

### How to run the artifact

The majority of the evaluation outputs are generated by the web app; two are generated by the test suite.

#### Running the web app

To run the web app, do the following in the repository root (where `$PWD` is assumed to expand to the current folder):
- `docker run -p 1234:1234 -v $PWD:/usr/src/app -it --entrypoint=/bin/bash fluid-webapp` to shell into Docker container with current directory mounted and HTTP port exposed
- `yarn install` to install application dependencies
- `yarn run bundle-app` to build app
- `yarn parcel serve index.html` to start web server
- open a browser (preferably Chrome) at `http://localhost:1234/`.

Some text will load (including a heading saying "Fluid 0.4"); if everything is working correctly, the images required for Evaluation Steps 1-3 will load after about 30 seconds.

#### Running the test suite

Alternatively, to run tests:
- shell into container using command above
- `yarn install` to install application dependencies (if not already done)
- `yarn run clean-tests && yarn build-tests` to build tests
- `yarn run tests` to run the tests in Chrome headless mode

The compiled output for the tests is written to `dist/test/app.js`. The tests (there are 56)_ should pass in about 4 minutes. The tests serve to validate the implementation as a whole, as well as generating the raw output for Evaluation Step 4, as described below.

#### Running individual tests

Running an individual test takes a small amount of manual effort: one must replace the top-level invocation of the test suite by a call to a predefined function called `test_scratchpad`, which runs a list of specific tests. Specifically:

* In `test/Main.purs`, in the first function of the file, comment out `tests = [ test_desugaring, test_misc, test_bwd, test_linking, test_graphics ]` and
uncomment `tests = [ test_scratchpad ]`.
* Insert the code for the test you want to run into the list in `test_scratchpad`. If you want to run a specific test, you can copy the required test invocation code from any of `test_desugaring`, `test_misc`, `test_bwd`, `test_linking` and `test_graphics`. Creating your own test from scratch takes a certain understanding of the system; we would be happy to help with this.
* Then running the whole test suite, using the instructions above, will run only the test(s) specified in `test_scratchpad`.

## Evaluation instructions

### Step 1

The raw ingredients for Figure 1 are served by the web app as part of a web page. To verify, follow the instructions above for running the web app. The web page `http://localhost:1234/` should then display three bar charts; the first and penultimate of these correspond to the two bar charts in Fig. 1. The two tabular views correspond to the two differently-highlighted parts of the table in the middle of Fig 1.  The relevant PureScript code is the function ```linkingFigs``` in `src/app/Demo.purs`, which loads the Fluid source code for the bar chart, shown at the bottom of Fig. 2. This can be found in `fluid/example/linking/bar-chart.fld`.

We made the following manual changes to the images for inclusion in the paper: we added the "selection 1" and "selection 2" arrows; we changed the selection color on the right-hand side from orange to blue; and we combined the two tabular views into a single table.

### Step 2

The raw ingredients for Figure 2 are also generated by the web app, which we assume has already been built using the instructions above. The first three images displayed on the web page `http://localhost:1234/` were combined to form Figure 2. The relevant PureScript code is the function ```linkingFigs``` in `src/app/Demo.purs`, which as well as loading the bar chart code (as described in from Step 1) also loads the Fluid code for the line chart shown at the bottom of Fig. 2. This can be found in `fluid/example/linking/line-chart.fld`.

We made the following manual changes to the images for inclusion in the paper: we added the "what data to do I need?" and "what needs this data?" arrows.

### Step 3

The raw ingredients for Figure 13 are also generated by the web app, which we assume has already been built using the instructions above. The matrices shown in the lower half of `http://localhost:1234/` contain the raw ingredients of Fig. 13; the first row of matrices, headed "Needs relation (and round-trip)", were combined to produce Fig. 13a; the second row of matrices, headed "Needed-by relation (and round-trip)", were combined to produce Fig. 13b.

The Fluid source code used for this example can be found in `fluid/lib/convolution.fld` and `fluid/example/slicing/conv-emboss.fld`. This example is also verified by the function `test_bwd` in `test/Main.purs`, which runs the test case `fluid/example/slicing/conv-emboss.fld` with the output expectation `conv-emboss.expect.fld`, found in the same folder. This can be run by following the instructions above for running the test suite.

We made the following manual changes to the images for inclusion in the paper: we added the "what do I need?", "what only needs me?", "what needs me?", and "what do only I need?" arrows; the vertical bars separating inputs and outputs; and the headings "input selection A", "output selection B", etc.

### Step 4

The raw ingredients for Figure 16 (see above) are generated by the test function ```testBwd``` of `src/test/Main.purs`, running the test called `section-5-example`. To verify, follow the instructions above for running the test suite. The relevant Fluid source file is `fluid/example/slicing/section-5-example.fld`, with the output expectations in `fluid/example/slicing/section-5-example-1.expect.fld` (for left-hand side of Fig. 16) and `fluid/example/slicing/section-5-example-2.expect.fld` (for right-hand side of Fig. 16). In these and other test expectations, underscores are used to indicate "selected" data values. You can also run these two test cases on their own, by following the instructions above for running individual tests.

We made the following manual changes to the images for inclusion in the paper: we removed the underscores indicating selections and used appropriately shaded backgrounds instead.

## Additional artifact description

The Fluid source code used for the tests and web app are found in the `fluid/example` directory. The core library is found in `lib/prelude`, with the matrix convolution functions in `lib/convolution`. The dataset used for the linking examples is in the folder `fluid/dataset`. Fluid test files have the extension `.fld`; the examples in the `fluid/slicing` folder also come with `.expect.fld` files, which capture the expected selection state on the program that arises from a backward slice.

### Overview of tests and test infrastructure

#### Test helpers

These are defined in `test/Util.purs`. Usage examples can be found in `test/Main.purs`. Note that most tests perform a forward and backward round-trip as a sanity-check, but only `testBwd` and `testLink` actually verify that the analysis results are as expected.

- `test`: The most basic kind of test. Desugars the test program, evaluates it to obtain a trace, and performs a forward and backward analysis (over both evaluation and desugaring) to sanity-check that they execute without runtime failure. The output of the round-trip is printed to the console, and the (prettyprinted) output is compared against a supplied expected value. (Typically there is no selection, so the comparison is of unselected values.)

- `testWithDataset`: Similar to `test`, but additionally loads a dataset (also represented as a `.fld` source file) and ensures that the test runs in an environment where that dataset has been bound to a variable. Only used for the legacy graphics tests (see below).

- `testBwd` Similar to `test`, but additionally checks that the backward analysis step produces an expected selection on the (prettyprinted) source program. The emitted source selection is printed to the console along with the result of the round-trip, which will now contain selection information. The prettyprinter will add underscores to selected expressions and values, allowing the expected source program selection to be provided as an additional source file (with extension `.expected.fld` in the same folder as the test) where selected expressions are demarked by underscores. Note, however, that the underscore notation is not supported by the parser, and so one cannot initiate a forward analysis by adding underscores to a `.fld` source file.

- `testLink` Tests the linking feature. Given two test programs and a (shared) dataset, desugars and evaluates both programs, applies a selection to the output of the first program, performs a backward analysis to produce a selection on the shared data, and then performs the De Morgan dual of the forward analysis to produce a selection on the output of the second program. Compares the (prettyprinted) output of the second program against a supplied expected value, which must use underscores to represent the expected selection. The output of the second program is printed to the console.

#### Test suite

The test suite is defined in `test/Main.purs` and is organised into the following test functions.

- `test_scratchpad` is useful for running tests one at a time; see **Running individual tests** above.

- `test_linking` defines three linking tests, using the helper `testLink`. The source programs are in `fluid/example/linking`. There are tests for the bar chart/line chart and convolution examples in the paper, and also a simple linking test involving (nested) pairs.

- `test_bwd` defines several tests of the backwards analysis, using the `testBwd` helper. The source programs are in `fluid/example/slicing`; each `.fld` file is paired with a `.expect.fld` containing the expectation for the source program selection.

- `test_desugaring` defines several tests which exercise the desugaring, using the `test` helper. The tests only check that the program desugars and executes correctly, not that the (source) program desugars to the expected core representation.

- `test_misc` defines several tests which verify that various primitives, library functions and data types work as expected.

- `test_graphics` tests the graphics library developed for the 0.3 release (since deprecated).

### Creating your own tests

Reviewers may wish to experiment with different Fluid source files and test expectations; we would be happy to assist with this.
